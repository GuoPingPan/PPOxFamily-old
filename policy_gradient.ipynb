{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Policy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "\n",
    "pg_data = namedtuple('pg_data', ['logit', 'action', 'return_'])\n",
    "pg_loss = namedtuple('pg_loss', ['policy_loss', 'entropy_loss'])\n",
    "\n",
    "def pg_error(data: namedtuple) -> namedtuple:\n",
    "\n",
    "    logit, action, return_ = data\n",
    "\n",
    "    # 用 torch 根据 policy 的数据拟合一个 \\pi(action|state) 的分布\n",
    "    dist = torch.distributions.categorical.Categorical(logits=logit)\n",
    " \n",
    "    # 计算实际 action 对应的概率值\n",
    "    log_prob = dist.log_prob(action)\n",
    "\n",
    "\n",
    "    # key: 这里的 loss 是乘上了一个负号，因为 RL 中是想要目标函数最大，而 torch 则是求最小，因此要变换一下\n",
    "    policy_loss =  - (return_ * log_prob).mean()\n",
    "\n",
    "    # entropy = \\pi*log(\\pi)\n",
    "    entropy_loss = dist.entropy().mean()\n",
    "\n",
    "    return pg_loss(policy_loss, entropy_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pg():\n",
    "    B, N = 4, 32\n",
    "    logit = torch.randn(B, N)\n",
    "    logit.requires_grad = True # 4,32\n",
    "    action = torch.randint(0, N, size=(B, )) # 4\n",
    "    return_ = torch.randn(B) * 2 # 4\n",
    "\n",
    "    data = pg_data(logit, action, return_)\n",
    "    loss = pg_error(data)\n",
    "    \n",
    "    assert all([l.shape == tuple() for l in loss])\n",
    "    assert logit.grad is None\n",
    "\n",
    "    total_loss = sum(loss)\n",
    "    total_loss.backward()\n",
    "    print(f'gradient = {logit.grad}')\n",
    "    assert isinstance(logit.grad, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient = tensor([[ 3.5486e-03,  4.1057e-03, -5.9870e-03, -1.2126e-02,  4.1362e-03,\n",
      "          4.4808e-03, -1.1184e-02,  4.4520e-03,  4.3979e-03,  2.6895e-03,\n",
      "          3.2572e-03, -4.0002e-03, -1.3826e-02,  4.4099e-03,  1.5390e-03,\n",
      "          4.2445e-03,  4.3016e-03,  4.4508e-03,  2.4397e-03,  3.6939e-03,\n",
      "          4.0700e-03,  4.4068e-03, -3.8916e-02,  4.1086e-03,  4.4745e-03,\n",
      "          4.4634e-03,  4.3491e-03,  3.8016e-03, -1.1592e-02,  4.4277e-03,\n",
      "          3.6870e-03,  3.6957e-03],\n",
      "        [ 2.5218e-03,  1.2896e-03, -5.0744e-03,  3.7747e-03,  3.6985e-03,\n",
      "          3.9812e-03,  3.0884e-03,  3.6825e-03,  1.9921e-03,  1.6325e-03,\n",
      "          1.6994e-03,  4.6582e-02, -8.5802e-03,  2.1367e-03,  3.4858e-03,\n",
      "          2.6416e-03, -5.3362e-02,  5.3370e-04,  3.8763e-03,  3.0482e-03,\n",
      "          2.3109e-03,  3.3736e-03, -1.4816e-02,  3.7264e-03,  2.3092e-03,\n",
      "         -3.9912e-02,  3.9392e-03,  3.8367e-03,  2.2680e-03,  3.9189e-03,\n",
      "          2.5579e-03,  3.8398e-03],\n",
      "        [ 1.2087e-03, -5.5561e-04, -1.2672e-02,  1.7767e-03, -1.2940e-03,\n",
      "         -8.7706e-04, -4.8665e-02,  1.7745e-03,  2.6055e-05,  1.5701e-03,\n",
      "         -7.6932e-03, -3.7947e-02,  2.1671e-01, -2.9071e-02,  1.6843e-03,\n",
      "          9.3061e-04, -4.0344e-02, -3.5392e-02, -1.2088e-03,  4.0466e-04,\n",
      "         -6.6960e-05, -3.3439e-03, -1.3953e-03,  1.7678e-03,  1.0771e-03,\n",
      "         -1.2652e-04, -1.0647e-02,  4.2436e-04,  1.1651e-03,  5.1395e-04,\n",
      "          1.6330e-03, -1.3709e-03],\n",
      "        [ 7.3656e-03,  6.3021e-03,  5.2062e-03,  6.6699e-03,  2.6357e-03,\n",
      "          3.7234e-03,  8.5244e-03,  8.6727e-03, -1.3450e-02,  7.2052e-03,\n",
      "          1.8756e-03,  5.2350e-03,  8.8294e-03,  8.0537e-03,  8.2022e-03,\n",
      "          7.3300e-03,  7.9881e-03,  8.8408e-03,  7.1445e-03, -6.2569e-02,\n",
      "          5.2983e-03,  6.2884e-03,  8.7880e-03, -1.1447e-01,  5.7517e-03,\n",
      "          4.5007e-03,  6.6504e-03,  7.8347e-03,  6.3531e-03,  4.7898e-03,\n",
      "          6.0800e-03,  8.3487e-03]])\n"
     ]
    }
   ],
   "source": [
    "test_pg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9a238c1dd6579231cf311ac7fb8324fa58175f6a14baf19d4e70b11c8b25d83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
